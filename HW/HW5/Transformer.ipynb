{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-EnY-Vm1a4V"
      },
      "source": [
        "- Full Name: **Seyyed Amirmahdi Sadrzadeh**\n",
        "- Student ID: **401102015**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbdExQRd1a4X"
      },
      "source": [
        "# üß† Homework 4: Transformer for Sentiment Analysis\n",
        "\n",
        "## üìå Objective\n",
        "\n",
        "In this assignment, you will **implement a Transformer-based model for sentiment analysis** on the IMDb movie review dataset. You will:\n",
        "\n",
        "- üßπ Preprocess and clean real-world text data.\n",
        "- üèóÔ∏è Build a Transformer classifier from scratch (including positional encoding).\n",
        "- üß† Train the model to classify IMDb reviews as **positive** or **negative**.\n",
        "- üìà Evaluate model performance on the test set.\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Learning Goals\n",
        "\n",
        "By the end of this assignment, you should be able to:\n",
        "\n",
        "- Understand how the Transformer encoder works in NLP.\n",
        "- Implement tokenization, padding, and vocabulary creation.\n",
        "- Train a Transformer-based model for text classification.\n",
        "- Measure and interpret model performance on a real-world dataset.\n",
        "\n",
        "---\n",
        "\n",
        "## üì¶ Dataset\n",
        "\n",
        "We use the **IMDb movie reviews dataset**:\n",
        "\n",
        "- Contains 50,000 highly polar movie reviews (25,000 for training and 25,000 for testing).\n",
        "- Each review is labeled as either **positive (1)** or **negative (0)**.\n",
        "- You will clean the raw text, tokenize it, and build a vocabulary before training.\n",
        "\n",
        "---\n",
        "\n",
        "## üèóÔ∏è Model Architecture\n",
        "\n",
        "You will build a **Transformer Encoder** model that includes:\n",
        "\n",
        "- Word Embedding Layer\n",
        "- Positional Encoding Layer\n",
        "- Multi-head Self-Attention Blocks\n",
        "- Feedforward Layers\n",
        "- Final Classification Head\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öôÔ∏è Training Details\n",
        "\n",
        "- Optimizer: `Adam`\n",
        "- Loss Function: `CrossEntropyLoss`\n",
        "- Batch Size: `32`\n",
        "- Learning Rate: `1e-3`\n",
        "- Epochs: `5`\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Evaluation Criteria\n",
        "\n",
        "Your final implementation will be evaluated on:\n",
        "\n",
        "- ‚úÖ Correct implementation of the Transformer classifier.\n",
        "- ‚úÖ Clean and modular code (e.g., `Dataset`, `Dataloader`, `Model`, `Train` functions).\n",
        "- ‚úÖ Accuracy on the IMDb test set.\n",
        "- ‚úÖ Proper text preprocessing and vocabulary handling.\n",
        "- ‚úÖ Well-commented and readable code.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S8nIa0oa1a4Y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import tarfile\n",
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pNxuxXC01a4Z",
        "outputId": "3091c081-3a6b-46c3-b094-799318353758",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading IMDb dataset...\n",
            "Extracting...\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "## Do not edit part\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def download_imdb(data_path=\"./imdb\"):\n",
        "    url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "    os.makedirs(data_path, exist_ok=True)\n",
        "    filepath = os.path.join(data_path, \"aclImdb_v1.tar.gz\")\n",
        "\n",
        "    if not os.path.exists(filepath):\n",
        "        print(\"Downloading IMDb dataset...\")\n",
        "        r = requests.get(url, stream=True)\n",
        "        with open(filepath, \"wb\") as f:\n",
        "            for chunk in r.iter_content(chunk_size=1024): f.write(chunk)\n",
        "\n",
        "        print(\"Extracting...\")\n",
        "        with tarfile.open(filepath, \"r:gz\") as tar:\n",
        "            tar.extractall(path=data_path)\n",
        "    print(\"Done.\")\n",
        "\n",
        "download_imdb()\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"<.*?>\", \"\", text)\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
        "    return text.lower()\n",
        "\n",
        "def load_imdb_data(base_path, split='train'):\n",
        "    data = []\n",
        "    for label in ['pos', 'neg']:\n",
        "        folder = os.path.join(base_path, f'aclImdb/{split}/{label}')\n",
        "        for fname in os.listdir(folder):\n",
        "            with open(os.path.join(folder, fname), 'r', encoding='utf8') as f:\n",
        "                text = clean_text(f.read())\n",
        "                data.append((text, 1 if label == 'pos' else 0))\n",
        "    return data\n",
        "\n",
        "train_raw = load_imdb_data(\"./imdb\", split='train')\n",
        "test_raw = load_imdb_data(\"./imdb\", split='test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "m4HWhtXa1a4Z"
      },
      "outputs": [],
      "source": [
        "## Do not edit part\n",
        "def tokenize(text):\n",
        "    return text.split()\n",
        "\n",
        "# Build vocab\n",
        "counter = Counter()\n",
        "for text, _ in train_raw:\n",
        "    counter.update(tokenize(text))\n",
        "\n",
        "vocab = {\"<pad>\": 0, \"<unk>\": 1}\n",
        "for word, freq in counter.items():\n",
        "    if freq >= 5:\n",
        "        vocab[word] = len(vocab)\n",
        "\n",
        "def encode(text):\n",
        "    return [vocab.get(w, vocab[\"<unk>\"]) for w in tokenize(text)]\n",
        "\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = [(encode(text), label) for text, label in data]\n",
        "    def __len__(self): return len(self.data)\n",
        "    def __getitem__(self, idx): return self.data[idx]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    texts, labels = zip(*batch)\n",
        "    texts = [torch.tensor(x) for x in texts]\n",
        "    texts = torch.nn.utils.rnn.pad_sequence(texts, batch_first=True, padding_value=vocab[\"<pad>\"])\n",
        "    return texts.to(device), torch.tensor(labels).to(device)\n",
        "\n",
        "train_dataset = IMDBDataset(train_raw)\n",
        "test_dataset = IMDBDataset(test_raw)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6gVrcM9v1a4Z"
      },
      "outputs": [],
      "source": [
        "## To do: complete the PositionalEncoding module\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(np.log(10000.0) / d_model))\n",
        "        ## Sin , Cos positional encoding\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)        # even dims\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)        # odd dims\n",
        "        self.pe = pe.unsqueeze(0)\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)].to(x.device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Km7lMwdL1a4a"
      },
      "outputs": [],
      "source": [
        "## To do: complete MultiheadAttention module\n",
        "class MultiheadAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "\n",
        "        assert self.head_dim * num_heads == embed_dim, \"embed_dim must be divisible by num_heads\"\n",
        "\n",
        "        self.q_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.k_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.v_proj = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, query, key, value, key_padding_mask=None):\n",
        "        batch_size = query.size(1)\n",
        "\n",
        "        # Project inputs to query, key, value\n",
        "        q = self.q_proj(query).view(-1, batch_size * self.num_heads, self.head_dim).transpose(0, 1)\n",
        "        k = self.k_proj(key).view(-1, batch_size * self.num_heads, self.head_dim).transpose(0, 1)\n",
        "        v = self.v_proj(value).view(-1, batch_size * self.num_heads, self.head_dim).transpose(0, 1)\n",
        "\n",
        "        # Scaled dot-product attention\n",
        "        attn_output, attn_weights = self.scaled_dot_product_attention(q, k, v)\n",
        "\n",
        "        # Concatenate heads and project back to original dimension\n",
        "        attn_output = attn_output.transpose(0, 1).contiguous().view(-1, batch_size, self.embed_dim)\n",
        "        attn_output = self.dropout(self.out_proj(attn_output))\n",
        "\n",
        "        return attn_output, attn_weights\n",
        "\n",
        "    ## To do\n",
        "    def scaled_dot_product_attention(self, q, k, v):\n",
        "        attn_scores = torch.bmm(q, k.transpose(1, 2)) / np.sqrt(self.head_dim)\n",
        "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "        output = torch.matmul(attn_weights, v)\n",
        "        return output, attn_weights\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dSdJkd3C1a4a"
      },
      "outputs": [],
      "source": [
        "## To do: complete the forward function\n",
        "\n",
        "class TransformerEncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiheadAttention(d_model, nhead, dropout=dropout)\n",
        "        # Implementation of Feedforward model\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        # Self attention\n",
        "        src2 = self.self_attn(src, src, src)[0]\n",
        "        src = src + self.dropout1(src2)\n",
        "        src = self.norm1(src)\n",
        "\n",
        "        # Feedforward\n",
        "        src2 = self.linear2(self.dropout(torch.relu(self.linear1(src))))\n",
        "        src = src + self.dropout2(src2)\n",
        "        src = self.norm2(src)\n",
        "        return src\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LFGEz9j71a4a"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, encoder_layer, num_layers):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([copy.deepcopy(encoder_layer) for _ in range(num_layers)])\n",
        "\n",
        "    ## To do\n",
        "    def forward(self, src):\n",
        "        output = src\n",
        "        for layer in self.layers:\n",
        "            output = layer(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "z3ojY_Tr1a4a"
      },
      "outputs": [],
      "source": [
        "class TransformerClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=128, nhead=4, num_layers=2, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model, padding_idx=0)\n",
        "        self.pos_encoder = PositionalEncoding(d_model)\n",
        "\n",
        "        encoder_layer = TransformerEncoderLayer(d_model, nhead, d_model*2, dropout=0.1)\n",
        "        self.transformer = TransformerEncoder(encoder_layer, num_layers)\n",
        "\n",
        "        self.fc = nn.Linear(d_model, num_classes)\n",
        "\n",
        "    def forward(self, src):\n",
        "        ## get the embedding\n",
        "        x = self.embedding(src)\n",
        "        ## pos encode\n",
        "        x = self.pos_encoder(x)\n",
        "        x = x.permute(1, 0, 2)   # (seq_len, batch, dim)\n",
        "        x = self.transformer(x)\n",
        "        return self.fc(x[0])  # Use first token as representation\n",
        "model = TransformerClassifier(len(vocab)).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YdusbqTx1a4b"
      },
      "outputs": [],
      "source": [
        "## To do: complete the training loop\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(model, loader):\n",
        "    model.train()\n",
        "    total_loss, correct = 0, 0\n",
        "    for x, y in loader:\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)\n",
        "        loss = criterion(out, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        correct    += (out.argmax(1) == y).sum().item()\n",
        "    return total_loss / len(loader), correct / len(loader.dataset)\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            out = model(x)\n",
        "            correct += (out.argmax(1) == y).sum().item()\n",
        "    return correct / len(loader.dataset)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hgXzcNOB1a4b",
        "outputId": "73518932-a94c-4a24-9af3-cfebe8f647a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss 0.5923, Train Acc 0.6885, Test Acc 0.6845\n",
            "Epoch 2: Train Loss 0.5996, Train Acc 0.6794, Test Acc 0.6487\n",
            "Epoch 3: Train Loss 0.6078, Train Acc 0.6720, Test Acc 0.6748\n",
            "Epoch 4: Train Loss 0.5844, Train Acc 0.6966, Test Acc 0.6848\n",
            "Epoch 5: Train Loss 0.5936, Train Acc 0.6892, Test Acc 0.6618\n",
            "Epoch 6: Train Loss 0.5986, Train Acc 0.6721, Test Acc 0.6918\n",
            "Epoch 7: Train Loss 0.5494, Train Acc 0.7220, Test Acc 0.7378\n",
            "Epoch 8: Train Loss 0.5393, Train Acc 0.7330, Test Acc 0.7312\n",
            "Epoch 9: Train Loss 0.5330, Train Acc 0.7370, Test Acc 0.7374\n",
            "Epoch 10: Train Loss 0.5252, Train Acc 0.7412, Test Acc 0.7369\n",
            "Epoch 11: Train Loss 0.5198, Train Acc 0.7480, Test Acc 0.7436\n",
            "Epoch 12: Train Loss 0.5054, Train Acc 0.7586, Test Acc 0.7472\n",
            "Epoch 13: Train Loss 0.5006, Train Acc 0.7628, Test Acc 0.7480\n",
            "Epoch 14: Train Loss 0.4905, Train Acc 0.7668, Test Acc 0.7528\n",
            "Epoch 15: Train Loss 0.4743, Train Acc 0.7781, Test Acc 0.7657\n",
            "Epoch 16: Train Loss 0.4748, Train Acc 0.7771, Test Acc 0.7671\n",
            "Epoch 17: Train Loss 0.4683, Train Acc 0.7837, Test Acc 0.7682\n",
            "Epoch 18: Train Loss 0.4689, Train Acc 0.7848, Test Acc 0.7612\n",
            "Epoch 19: Train Loss 0.4634, Train Acc 0.7879, Test Acc 0.7683\n",
            "Epoch 20: Train Loss 0.4501, Train Acc 0.7958, Test Acc 0.7581\n"
          ]
        }
      ],
      "source": [
        "## Run and enjoy\n",
        "\n",
        "for epoch in range(20):\n",
        "    train_loss, train_acc = train(model, train_loader)\n",
        "    test_acc = evaluate(model, test_loader)\n",
        "    print(f\"Epoch {epoch+1}: Train Loss {train_loss:.4f}, Train Acc {train_acc:.4f}, Test Acc {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q06Arh721a4b"
      },
      "source": [
        "## üìù Bonus (Optional)\n",
        "\n",
        "- üîç Experiment with different model hyperparameters (e.g., `nhead`, `d_model`, `num_layers`).\n",
        "- üìä Plot training and validation accuracy over epochs.\n",
        "- üìå Use attention weights to interpret model focus.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PbEtgBOf8sGV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}