{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f540329",
   "metadata": {},
   "source": [
    "# Fineâ€‘tuning **mT5â€‘base** with **LoRA** for Informal â†’ Formal Style Transfer (Persian)\n",
    "\n",
    "Name:\n",
    "\n",
    "Student ID: \n",
    "\n",
    "Welcome! In this assignment, youâ€™ll build an application that converts informal Persian sentences to formal ones.\n",
    "\n",
    "You will:\n",
    "\n",
    "1. **Preâ€‘process** the *ParsMap* informalâ€“formal corpus with the `hazm` library.  \n",
    "2. **Compute** input/output *tokenâ€‘length statistics* to choose sensible `max_length` values.  \n",
    "3. **Fineâ€‘tune** the multilingual T5â€‘base model (`google/mt5-base`) using **Lowâ€‘Rank Adaptation (LoRA)**.  \n",
    "4. **Evaluate** your model with BLEU and **perplexity**.  \n",
    "5. **Explore** *stochastic decoding* strategies (temperature, topâ€‘k, nucleus) and discuss diversity vs. quality.\n",
    "\n",
    "Fill in each **`TODO`** region with code or text.  \n",
    "When you finish, submit the completed notebook with a brief discussion section at the end summarising your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe4473c",
   "metadata": {},
   "source": [
    "### Key References  \n",
    "\n",
    "| Topic | Paper |\n",
    "|-------|------------------------------|\n",
    "| Corpus | *Ehsani etâ€¯al.* â€œDeveloping an Informalâ€‘Formal Persian Corpus.â€ ğŸ‡®ğŸ‡· |\n",
    "| Model | *Xue etâ€¯al.* â€œmT5: A Massively Multilingual Preâ€‘trained Textâ€‘toâ€‘Text Transformer.â€ TACLÂ 2021 |\n",
    "| Fineâ€‘tuning | *Hu etâ€¯al.* â€œLoRA: Lowâ€‘Rank Adaptation of Large Language Models.â€ ICMLÂ 2022 |\n",
    "| Decoding | *Holtzman etâ€¯al.* â€œThe Curious Case of Neural Text Degeneration.â€ ICLRÂ 2020 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995a13c4",
   "metadata": {},
   "source": [
    "## 1Â Â·Â EnvironmentÂ &Â Dependencies  \n",
    "Run the next cell **once** (commented by default) to install the dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d343f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ› ï¸Â TODOÂ (âš ï¸Â Uncomment the next line if you are in a fresh environment)\n",
    "# !pip install transformers==4.40.1 peft==0.10.0 datasets==2.19.0 evaluate==0.4.1 accelerate==0.28.0 hazm==0.9.0 sacrebleu jupyterlab tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5493be58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¦ Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from hazm import Normalizer\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (AutoTokenizer, AutoModelForSeq2SeqLM,\n",
    "                          DataCollatorForSeq2Seq, Seq2SeqTrainingArguments,\n",
    "                          Seq2SeqTrainer)\n",
    "# TODO: add any other imports you need\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29e3ee9",
   "metadata": {},
   "source": [
    "##Â 2Â Â·Â DataÂ LoadingÂ &Â Normalisation  \n",
    "Point `FILE_PATH` to the Excel file of **ParsMap** dataset.\n",
    "1. Keep only the *informal* and *formal* columns.  \n",
    "2. Clean each sentence with `hazm.Normalizer`.  \n",
    "3. Create `train`, `validation`, and `test` splits (90â€¯/â€¯5â€¯/â€¯5â€¯%).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a468e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOÂ â†“\n",
    "FILE_PATH = \"PATH/TO/ParsMap.xlsx\"  # â†Â update this!\n",
    "\n",
    "# 1. Load the file\n",
    "df = pd.read_excel(FILE_PATH)[['inFormalForm', 'formalForm']].rename(\n",
    "    columns={'inFormalForm':'input', 'formalForm':'target'}\n",
    ")\n",
    "\n",
    "# 2. Normalise\n",
    "normalizer = Normalizer()\n",
    "df['input']  = df['input'].apply(normalizer.normalize)\n",
    "df['target'] = df['target'].apply(normalizer.normalize)\n",
    "\n",
    "# 3. Split to HF DatasetDict\n",
    "full_ds = Dataset.from_pandas(df)\n",
    "full_ds = full_ds.shuffle(seed=42)\n",
    "split_ds = full_ds.train_test_split(test_size=0.10, seed=42)\n",
    "val_test = split_ds['test'].train_test_split(test_size=0.50, seed=42)\n",
    "dataset = DatasetDict({'train': split_ds['train'],\n",
    "                       'validation': val_test['train'],\n",
    "                       'test': val_test['test']})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b80cf92",
   "metadata": {},
   "source": [
    "##Â 3Â Â·Â Tokenâ€‘lengthÂ Statistics  \n",
    "Before padding/truncation, inspect sequence lengths to decide `max_length` for **inputs** and **targets**.  \n",
    "Write a helper `length_stats()` that returns *min, max, mean, 95â€‘percentile*.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f2b7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOÂ â†“\n",
    "tokenizer = AutoTokenizer.from_pretrained('google/mt5-base', use_fast=False)\n",
    "\n",
    "def length_stats(texts):\n",
    "    \"\"\"Return descriptive statistics over tokenised length.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError\n",
    "\n",
    "input_stats  = length_stats(dataset['train']['input'])\n",
    "target_stats = length_stats(dataset['train']['target'])\n",
    "\n",
    "print('Input stats :', input_stats)\n",
    "print('Target stats:', target_stats)\n",
    "\n",
    "# Decide sensible values\n",
    "MAX_SOURCE_LEN = ...  # TODO\n",
    "MAX_TARGET_LEN = ...  # TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c68f9a4",
   "metadata": {},
   "source": [
    "###Â TokenisationÂ function  \n",
    "Complete `preprocess_function` so that it returns `input_ids`, `attention_mask`, and `labels` truncated/padded to the lengths chosen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd59c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOÂ â†“\n",
    "def preprocess_function(batch):\n",
    "    # YOUR CODE HERE\n",
    "    return model_inputs\n",
    "\n",
    "tokenised_ds = dataset.map(preprocess_function, batched=True, remove_columns=dataset['train'].column_names)\n",
    "tokenised_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a82fb6",
   "metadata": {},
   "source": [
    "##Â 4Â Â·Â ModelÂ &Â LoRAÂ Configuration  \n",
    "Instantiate *mT5â€‘base* and wrap it with **LoRA**.  \n",
    "Read the LoRA paper and, based on its insights and your available GPU resources, experiment with the *rankÂ r*, `lora_alpha`, and target modules.â€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5bd10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOÂ â†“\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    # r=,                     # TODO: tune\n",
    "    # lora_alpha=,            # TODO: tune\n",
    "    # target_modules=,        # TODO: tune\n",
    "    lora_dropout=0.10,\n",
    "    bias='none',\n",
    "    task_type='SEQ_2_SEQ_LM'\n",
    ")\n",
    "\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained('google/mt5-base')\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75687ce8",
   "metadata": {},
   "source": [
    "##Â 5Â Â·Â Fineâ€‘tuning  \n",
    "Define `Seq2SeqTrainingArguments` and train for **3 epochs**  \n",
    "Log training loss and evaluate on the validation set each epoch.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2046f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOÂ â†“\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "# TODO\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding='longest')\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenised_ds['train'],\n",
    "    eval_dataset=tokenised_ds['validation'],\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# ğŸš€ Train\n",
    "# trainer.train()  # â†Â uncomment when ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784b8efd",
   "metadata": {},
   "source": [
    "##Â 6Â Â·Â Inference  \n",
    "Generate the *formal* version of **5 custom informal sentences** using **greedy decoding** *and* your `MAX_TARGET_LEN`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903b6b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOÂ â†“\n",
    "example_inputs = [\n",
    "    \"ÙˆØ§Ø³Ù‡ Ú†ÛŒ Ø§ÛŒÙ†Ù‚Ø¯Ø± Ø¯ÛŒØ± Ø§ÙˆÙ…Ø¯ÛŒØŸ\",\n",
    "    # add 4 more\n",
    "]\n",
    "\n",
    "# Greedy decoding\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e604cf",
   "metadata": {},
   "source": [
    "##Â 7Â Â·Â Evaluation  \n",
    "Compute **BLEU** on the *test* split and report **perplexity** on *validation*.  \n",
    "Explain briefly what each metric captures for this task.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7292d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOÂ â†“\n",
    "import evaluate, math\n",
    "\n",
    "bleu = evaluate.load('sacrebleu')\n",
    "# 1. Generate predictions\n",
    "# 2. Compute BLEU and perplexity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3d1220",
   "metadata": {},
   "source": [
    "##Â 8Â Â·Â StochasticÂ DecodingÂ &Â DiversityÂ Analysis  \n",
    "\n",
    "Read *Holtzmanâ€¯etâ€¯al.Â 2020* â€” *The Curious Case of Neural Text Degeneration* â€” to understand how different **stochastic decoding** strategies (like temperature, topâ€‘k, and topâ€‘p sampling) can lead to generating multiple diverse outputs from the same input prompt.\n",
    "\n",
    "Implement these decoding strategies and experiment with several input examples to observe how the outputs vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef64fad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOÂ â†“\n",
    "def sample_outputs(prompt: str,\n",
    "                   num_return_sequences: int = 5,\n",
    "                   temperature: float = 0.7,\n",
    "                   top_k: int = 50,\n",
    "                   top_p: float = 1.0):\n",
    "    \"\"\"Generate *num_return_sequences* diverse outputs from the fineâ€‘tuned model.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "prompt = \"ØªÙˆ Ù…Ø·Ù…Ø¦Ù†ÛŒ Ú©Ù‡ Ø¨Ø§Ø¨Ø§ Ø¨Ù„Ø¯Ù‡ Ú¯Ø±Ù‡ Ø¯ÙˆØªØ§Ø¦ÛŒ Ø¨Ù‡ Ú©ÙØ´Ù… Ø¨Ø²Ù†Ù‡ ÙˆÙ‚ØªÛŒ Ú©Ù‡ Ù…Ù† ØµØ¨Ø­Ù‡Ø§ Ù…ÛŒØ®ÙˆØ§Ù… Ø¨Ø±Ù… Ù…Ø¯Ø±Ø³Ù‡ØŸ\"\n",
    "samples = sample_outputs(prompt, num_return_sequences=5, temperature=0.9, top_p=0.95)\n",
    "print(*samples, sep='\\n---\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f1b754",
   "metadata": {},
   "source": [
    "##Â 9Â Â·Â DiscussionÂ \n",
    "\n",
    "1. How did LoRA hyperâ€‘parameters influence training stability or performance?  \n",
    "2. **Deterministic vs. Stochastic Decoding**  \n",
    "   Briefly explain what deterministic decoding (e.g. greedy search, beam search) and stochastic decoding (e.g. temperature sampling, topâ€‘k/topâ€‘p nucleus sampling) mean, drawing on Holtzmanâ€¯etâ€¯al.Â 2020, *The Curious Case of Neural Text Degeneration*.\n",
    "3. Suggest one improvement to the data or model that could further boost formalisation quality.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da6b808",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "###Â Submission Checklist âœ…\n",
    "\n",
    "- [ ] All `TODO` blocks completed.  \n",
    "- [ ] Notebook runs endâ€‘toâ€‘end without errors (`Runtimeâ€¯â‡¾â€¯Restart & Run All`).  \n",
    "- [ ] Answers written in the *Discussion* section.  \n",
    "\n",
    "Good luck, and have fun experimenting! âœ¨\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0bac44",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
