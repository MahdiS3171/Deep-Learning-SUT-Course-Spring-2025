{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f540329",
   "metadata": {},
   "source": [
    "# Fine‑tuning **mT5‑base** with **LoRA** for Informal → Formal Style Transfer (Persian)\n",
    "\n",
    "Name:\n",
    "\n",
    "Student ID: \n",
    "\n",
    "Welcome! In this assignment, you’ll build an application that converts informal Persian sentences to formal ones.\n",
    "\n",
    "You will:\n",
    "\n",
    "1. **Pre‑process** the *ParsMap* informal–formal corpus with the `hazm` library.  \n",
    "2. **Compute** input/output *token‑length statistics* to choose sensible `max_length` values.  \n",
    "3. **Fine‑tune** the multilingual T5‑base model (`google/mt5-base`) using **Low‑Rank Adaptation (LoRA)**.  \n",
    "4. **Evaluate** your model with BLEU and **perplexity**.  \n",
    "5. **Explore** *stochastic decoding* strategies (temperature, top‑k, nucleus) and discuss diversity vs. quality.\n",
    "\n",
    "Fill in each **`TODO`** region with code or text.  \n",
    "When you finish, submit the completed notebook with a brief discussion section at the end summarising your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe4473c",
   "metadata": {},
   "source": [
    "### Key References  \n",
    "\n",
    "| Topic | Paper |\n",
    "|-------|------------------------------|\n",
    "| Corpus | *Ehsani et al.* “Developing an Informal‑Formal Persian Corpus.” 🇮🇷 |\n",
    "| Model | *Xue et al.* “mT5: A Massively Multilingual Pre‑trained Text‑to‑Text Transformer.” TACL 2021 |\n",
    "| Fine‑tuning | *Hu et al.* “LoRA: Low‑Rank Adaptation of Large Language Models.” ICML 2022 |\n",
    "| Decoding | *Holtzman et al.* “The Curious Case of Neural Text Degeneration.” ICLR 2020 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995a13c4",
   "metadata": {},
   "source": [
    "## 1 · Environment & Dependencies  \n",
    "Run the next cell **once** (commented by default) to install the dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d343f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🛠️ TODO (⚠️ Uncomment the next line if you are in a fresh environment)\n",
    "# !pip install transformers==4.40.1 peft==0.10.0 datasets==2.19.0 evaluate==0.4.1 accelerate==0.28.0 hazm==0.9.0 sacrebleu jupyterlab tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5493be58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from hazm import Normalizer\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (AutoTokenizer, AutoModelForSeq2SeqLM,\n",
    "                          DataCollatorForSeq2Seq, Seq2SeqTrainingArguments,\n",
    "                          Seq2SeqTrainer)\n",
    "# TODO: add any other imports you need\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29e3ee9",
   "metadata": {},
   "source": [
    "## 2 · Data Loading & Normalisation  \n",
    "Point `FILE_PATH` to the Excel file of **ParsMap** dataset.\n",
    "1. Keep only the *informal* and *formal* columns.  \n",
    "2. Clean each sentence with `hazm.Normalizer`.  \n",
    "3. Create `train`, `validation`, and `test` splits (90 / 5 / 5 %).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a468e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ↓\n",
    "FILE_PATH = \"PATH/TO/ParsMap.xlsx\"  # ← update this!\n",
    "\n",
    "# 1. Load the file\n",
    "df = pd.read_excel(FILE_PATH)[['inFormalForm', 'formalForm']].rename(\n",
    "    columns={'inFormalForm':'input', 'formalForm':'target'}\n",
    ")\n",
    "\n",
    "# 2. Normalise\n",
    "normalizer = Normalizer()\n",
    "df['input']  = df['input'].apply(normalizer.normalize)\n",
    "df['target'] = df['target'].apply(normalizer.normalize)\n",
    "\n",
    "# 3. Split to HF DatasetDict\n",
    "full_ds = Dataset.from_pandas(df)\n",
    "full_ds = full_ds.shuffle(seed=42)\n",
    "split_ds = full_ds.train_test_split(test_size=0.10, seed=42)\n",
    "val_test = split_ds['test'].train_test_split(test_size=0.50, seed=42)\n",
    "dataset = DatasetDict({'train': split_ds['train'],\n",
    "                       'validation': val_test['train'],\n",
    "                       'test': val_test['test']})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b80cf92",
   "metadata": {},
   "source": [
    "## 3 · Token‑length Statistics  \n",
    "Before padding/truncation, inspect sequence lengths to decide `max_length` for **inputs** and **targets**.  \n",
    "Write a helper `length_stats()` that returns *min, max, mean, 95‑percentile*.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f2b7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ↓\n",
    "tokenizer = AutoTokenizer.from_pretrained('google/mt5-base', use_fast=False)\n",
    "\n",
    "def length_stats(texts):\n",
    "    \"\"\"Return descriptive statistics over tokenised length.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError\n",
    "\n",
    "input_stats  = length_stats(dataset['train']['input'])\n",
    "target_stats = length_stats(dataset['train']['target'])\n",
    "\n",
    "print('Input stats :', input_stats)\n",
    "print('Target stats:', target_stats)\n",
    "\n",
    "# Decide sensible values\n",
    "MAX_SOURCE_LEN = ...  # TODO\n",
    "MAX_TARGET_LEN = ...  # TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c68f9a4",
   "metadata": {},
   "source": [
    "### Tokenisation function  \n",
    "Complete `preprocess_function` so that it returns `input_ids`, `attention_mask`, and `labels` truncated/padded to the lengths chosen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd59c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ↓\n",
    "def preprocess_function(batch):\n",
    "    # YOUR CODE HERE\n",
    "    return model_inputs\n",
    "\n",
    "tokenised_ds = dataset.map(preprocess_function, batched=True, remove_columns=dataset['train'].column_names)\n",
    "tokenised_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a82fb6",
   "metadata": {},
   "source": [
    "## 4 · Model & LoRA Configuration  \n",
    "Instantiate *mT5‑base* and wrap it with **LoRA**.  \n",
    "Read the LoRA paper and, based on its insights and your available GPU resources, experiment with the *rank r*, `lora_alpha`, and target modules.”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5bd10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ↓\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    # r=,                     # TODO: tune\n",
    "    # lora_alpha=,            # TODO: tune\n",
    "    # target_modules=,        # TODO: tune\n",
    "    lora_dropout=0.10,\n",
    "    bias='none',\n",
    "    task_type='SEQ_2_SEQ_LM'\n",
    ")\n",
    "\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained('google/mt5-base')\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75687ce8",
   "metadata": {},
   "source": [
    "## 5 · Fine‑tuning  \n",
    "Define `Seq2SeqTrainingArguments` and train for **3 epochs**  \n",
    "Log training loss and evaluate on the validation set each epoch.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2046f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ↓\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "# TODO\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding='longest')\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenised_ds['train'],\n",
    "    eval_dataset=tokenised_ds['validation'],\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# 🚀 Train\n",
    "# trainer.train()  # ← uncomment when ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784b8efd",
   "metadata": {},
   "source": [
    "## 6 · Inference  \n",
    "Generate the *formal* version of **5 custom informal sentences** using **greedy decoding** *and* your `MAX_TARGET_LEN`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903b6b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ↓\n",
    "example_inputs = [\n",
    "    \"واسه چی اینقدر دیر اومدی؟\",\n",
    "    # add 4 more\n",
    "]\n",
    "\n",
    "# Greedy decoding\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e604cf",
   "metadata": {},
   "source": [
    "## 7 · Evaluation  \n",
    "Compute **BLEU** on the *test* split and report **perplexity** on *validation*.  \n",
    "Explain briefly what each metric captures for this task.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7292d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ↓\n",
    "import evaluate, math\n",
    "\n",
    "bleu = evaluate.load('sacrebleu')\n",
    "# 1. Generate predictions\n",
    "# 2. Compute BLEU and perplexity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3d1220",
   "metadata": {},
   "source": [
    "## 8 · Stochastic Decoding & Diversity Analysis  \n",
    "\n",
    "Read *Holtzman et al. 2020* — *The Curious Case of Neural Text Degeneration* — to understand how different **stochastic decoding** strategies (like temperature, top‑k, and top‑p sampling) can lead to generating multiple diverse outputs from the same input prompt.\n",
    "\n",
    "Implement these decoding strategies and experiment with several input examples to observe how the outputs vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef64fad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ↓\n",
    "def sample_outputs(prompt: str,\n",
    "                   num_return_sequences: int = 5,\n",
    "                   temperature: float = 0.7,\n",
    "                   top_k: int = 50,\n",
    "                   top_p: float = 1.0):\n",
    "    \"\"\"Generate *num_return_sequences* diverse outputs from the fine‑tuned model.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "prompt = \"تو مطمئنی که بابا بلده گره دوتائی به کفشم بزنه وقتی که من صبحها میخوام برم مدرسه؟\"\n",
    "samples = sample_outputs(prompt, num_return_sequences=5, temperature=0.9, top_p=0.95)\n",
    "print(*samples, sep='\\n---\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f1b754",
   "metadata": {},
   "source": [
    "## 9 · Discussion \n",
    "\n",
    "1. How did LoRA hyper‑parameters influence training stability or performance?  \n",
    "2. **Deterministic vs. Stochastic Decoding**  \n",
    "   Briefly explain what deterministic decoding (e.g. greedy search, beam search) and stochastic decoding (e.g. temperature sampling, top‑k/top‑p nucleus sampling) mean, drawing on Holtzman et al. 2020, *The Curious Case of Neural Text Degeneration*.\n",
    "3. Suggest one improvement to the data or model that could further boost formalisation quality.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da6b808",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Submission Checklist ✅\n",
    "\n",
    "- [ ] All `TODO` blocks completed.  \n",
    "- [ ] Notebook runs end‑to‑end without errors (`Runtime ⇾ Restart & Run All`).  \n",
    "- [ ] Answers written in the *Discussion* section.  \n",
    "\n",
    "Good luck, and have fun experimenting! ✨\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0bac44",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
